name: "Zeiler"

input: "data"
input_dim: 1
input_dim: 256
input_dim: 2
input_dim: 2

layer {
   name: "conv_proposal1"
   type: "Convolution"
   bottom: "data"
   top: "conv_proposal1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 256
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "relu_proposal1"
   type: "ReLU"
   bottom: "conv_proposal1"
   top: "conv_proposal1"
}

layer {
   name: "proposal_cls_score1"
   type: "Convolution"
   bottom: "conv_proposal1"
   top: "proposal_cls_score1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output:  2   # 2(bg/fg) * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}



#-----------------------output------------------------

# to enable the calculation of softmax loss, we first reshape blobs related to SoftmaxWithLoss
layer {
   bottom: "proposal_cls_score1"
   top: "proposal_cls_score_reshape"
   name: "proposal_cls_score_reshape"
   type: "Reshape"
   reshape_param{
	   shape {
			dim: 0 
			dim: 2
			dim: -1 
			dim: 0
		}
	}
}


layer {
   name: "proposal_cls_prob"
   type: "Softmax"
   bottom: "proposal_cls_score_reshape"
   top: "proposal_cls_prob"

}

layer {
	name: "pool_score"
	type: "Pooling"
	bottom: "proposal_cls_prob"
	top: "pool_score"
	pooling_param {
		kernel_size: 2
		stride: 1
		pad: 0#1
		pool: AVE
	}
}
